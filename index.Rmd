---
title: "Joares May: Jaguar data exploration"
author:
  - Chris Beirne
site: bookdown::test-bookdown
output: bookdown::gitbook
documentclass: book
biblio-style: apalike
link-citations: yes
editor_options: 
  chunk_output_type: console
---

This workbook details the error checking and analysis for the Mato Grosso jaguars. 

The work will proceed in three steps.

1) Error checking and filtering.

2) GIS data exploration

3) Modelling

Below is a short summary of the individuals we have data for.


# Raw data

```{r c01, echo=F, message=F, include=F}
knitr::opts_chunk$set(echo = FALSE, message=F, warning=F)

#library(rgdal) 
library(dplyr)
library(leaflet)
library(units)
library(sf)
library(viridis)
library(kableExtra)
library(lubridate)
library(plotly)
## Load packages for google drive ----
library(googledrive)
library(purrr)
library(readxl)
library(geosphere)
library(foreach)
#library(maptools)
library(leaflet.extras)
#library(rnaturalearth)
library(terra)
library(ggplot2)
library(atlastools)
library(ctmm)

 
options(googledrive_quiet = TRUE)

# For when the trapping effort file is sorted
googledrive::drive_auth(path = Sys.getenv("GOOGLE_AUTHENTICATION_CREDENTIALS"))

# ## Find Google Drive folder 'Centre Circle Data & Info'
# data_path <- "data" 
# dir.create(data_path) 

# Get the habitat raster 
#drive_download(as_id("1zDN1uh_ioOdIFATp9Q18bYTukygNo52t"), overwrite=T)

# Import passcodes
#MOVE_PASS <- Sys.getenv("MOVEBANK_PASSWORD")
#MOVE_USE  <- Sys.getenv("MOVEBANK_USERNAME")

#loginStored <- movebankLogin(username=MOVE_USE, 
#                             password=MOVE_PASS)

# Download the jaguar data
dir.create("data/")
dir.create("data/raw_collar/")

# Import the locations
jag_dirs <- googledrive::drive_ls(path=as_id("https://drive.google.com/drive/folders/1reuZmFYueXVi-oiWSPCURbC3FTnKSzjq"))

# Download my key
drive_download(jag_dirs[1,], path="data/chris_key_data_files",type="csv", overwrite=T)
collar_files <- read.csv("data/chris_key_data_files.csv", header=T)

## Used the below to create my key
# # Remove the unrelated elements
jag_dirs <- jag_dirs[!(jag_dirs$name %in% c("Pandora TM", "Vivara TM", "Colares onÃ§as", "chris_key_data_files")),]
# i <- 31
# for(i in 1:nrow(jag_dirs))
# {
# print(i)
# print(jag_dirs[i,])
# tmp <- drive_ls(jag_dirs$id[i])
# print(tmp)
# }

# Import the key files
for(i in 28:nrow(collar_files))
{
  if(is.na(collar_files$id[i])==F)
  {
  drive_download(as_id(collar_files$id[i]), path=paste0("data/raw_collar/", collar_files$name[i],"_", collar_files$year[i], ".csv"), overwrite=T)
  }
}

file_locs <- data.frame(file=list.files("data/raw_collar"), name=NA, year=NA)

tmp <- strsplit(file_locs$file, "_")
file_locs[,c("name", "year")] <- do.call(rbind,tmp)
# Strip out .csv
file_locs$year <- substr(file_locs$year,1,4)
# Remove the file end

tmp <- as.data.frame(table(file_locs$name))
colnames(tmp) <- c("name", "years")


```

We have `r length(unique(tmp$name))` individuals with data, with between `r min(tmp$year)` and `r max(tmp$year)` years. Most individuals are tracked for one year. 

```{r c01_summary, echo=F, message=F, eval=T}

kbl(tmp) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

#test <- read.csv("data/raw_collar/Mono_unk.csv")
#as.Date(test$ObservationTime, origin =  "1969-12-31 24:00:00")
#as.POSIXct(test$ObservationTime, origin="1970-01-01")

```


